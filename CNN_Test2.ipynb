{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_Test2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"syumc3ud2JBd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f441934e-a371-4803-fc61-befba5214408","executionInfo":{"status":"ok","timestamp":1574116602651,"user_tz":420,"elapsed":2303,"user":{"displayName":"Erica Holswade","photoUrl":"","userId":"10344212883483634520"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras.datasets import cifar10, mnist\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n","from tensorflow.keras.layers import MaxPooling2D\n","import numpy as np\n","import scipy\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","from google.colab import drive\n","from google.colab import files\n","\n","np.random.seed(0)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"DswfcaJk2Unp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"0b4d2f6c-0d2f-42c7-a01e-7b8e6a322bfa","executionInfo":{"status":"ok","timestamp":1574116605174,"user_tz":420,"elapsed":4809,"user":{"displayName":"Erica Holswade","photoUrl":"","userId":"10344212883483634520"}}},"source":["#!pip install --upgrade tensorflow==2.0"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[31mERROR: Operation cancelled by user\u001b[0m\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/base_command.py\", line 153, in _main\n","    status = self.run(options, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py\", line 382, in run\n","    resolver.resolve(requirement_set)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/legacy_resolve.py\", line 201, in resolve\n","    self._resolve_one(requirement_set, req)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/legacy_resolve.py\", line 365, in _resolve_one\n","    abstract_dist = self._get_abstract_dist_for(req_to_install)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/legacy_resolve.py\", line 301, in _get_abstract_dist_for\n","    skip_reason = self._check_skip_installed(req)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/legacy_resolve.py\", line 271, in _check_skip_installed\n","    self.finder.find_requirement(req_to_install, upgrade=True)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/index.py\", line 879, in find_requirement\n","    req.name, specifier=req.specifier, hashes=hashes,\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/index.py\", line 861, in find_best_candidate\n","    candidates = self.find_all_candidates(project_name)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/index.py\", line 791, in find_all_candidates\n","    collected_links = self._link_collector.collect_links(project_name)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/collector.py\", line 542, in collect_links\n","    pages_links[page.url] = list(parse_links(page))\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/collector.py\", line 258, in parse_links\n","    namespaceHTMLElements=False,\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/html5lib/html5parser.py\", line 47, in parse\n","    return p.parse(doc, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/html5lib/html5parser.py\", line 289, in parse\n","    self._parse(stream, False, None, *args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/html5lib/html5parser.py\", line 134, in _parse\n","    self.mainLoop()\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/html5lib/html5parser.py\", line 243, in mainLoop\n","    new_token = phase.processEndTag(new_token)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/html5lib/html5parser.py\", line 485, in processEndTag\n","    return self.endTagHandler[token[\"name\"]](token)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/html5lib/html5parser.py\", line 1480, in endTagFormatting\n","    token[\"name\"])\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/html5lib/treebuilders/base.py\", line 269, in elementInActiveFormattingElements\n","    def elementInActiveFormattingElements(self, name):\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/main.py\", line 47, in main\n","    return command.main(cmd_args)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/base_command.py\", line 103, in main\n","    return self._main(args)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/base_command.py\", line 183, in _main\n","    logger.debug('Exception information:', exc_info=True)\n","  File \"/usr/lib/python3.6/logging/__init__.py\", line 1296, in debug\n","    self._log(DEBUG, msg, args, **kwargs)\n","  File \"/usr/lib/python3.6/logging/__init__.py\", line 1444, in _log\n","    self.handle(record)\n","  File \"/usr/lib/python3.6/logging/__init__.py\", line 1454, in handle\n","    self.callHandlers(record)\n","  File \"/usr/lib/python3.6/logging/__init__.py\", line 1516, in callHandlers\n","    hdlr.handle(record)\n","  File \"/usr/lib/python3.6/logging/__init__.py\", line 865, in handle\n","    self.emit(record)\n","  File \"/usr/lib/python3.6/logging/handlers.py\", line 73, in emit\n","    logging.FileHandler.emit(self, record)\n","  File \"/usr/lib/python3.6/logging/__init__.py\", line 1072, in emit\n","    StreamHandler.emit(self, record)\n","  File \"/usr/lib/python3.6/logging/__init__.py\", line 994, in emit\n","    msg = self.format(record)\n","  File \"/usr/lib/python3.6/logging/__init__.py\", line 840, in format\n","    return fmt.format(record)\n","  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/utils/logging.py\", line 151, in format\n","    formatted = super(IndentingFormatter, self).format(record)\n","  File \"/usr/lib/python3.6/logging/__init__.py\", line 585, in format\n","    record.exc_text = self.formatException(record.exc_info)\n","  File \"/usr/lib/python3.6/logging/__init__.py\", line 535, in formatException\n","    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n","  File \"/usr/lib/python3.6/traceback.py\", line 104, in print_exception\n","    type(value), value, tb, limit=limit).format(chain=chain):\n","  File \"/usr/lib/python3.6/traceback.py\", line 509, in __init__\n","    capture_locals=capture_locals)\n","  File \"/usr/lib/python3.6/traceback.py\", line 364, in extract\n","    f.line\n","  File \"/usr/lib/python3.6/traceback.py\", line 286, in line\n","    self._line = linecache.getline(self.filename, self.lineno).strip()\n","  File \"/usr/lib/python3.6/linecache.py\", line 16, in getline\n","    lines = getlines(filename, module_globals)\n","  File \"/usr/lib/python3.6/linecache.py\", line 47, in getlines\n","    return updatecache(filename, module_globals)\n","  File \"/usr/lib/python3.6/linecache.py\", line 136, in updatecache\n","    with tokenize.open(fullname) as fp:\n","  File \"/usr/lib/python3.6/tokenize.py\", line 454, in open\n","    encoding, lines = detect_encoding(buffer.readline)\n","  File \"/usr/lib/python3.6/tokenize.py\", line 423, in detect_encoding\n","    first = read_or_stop()\n","  File \"/usr/lib/python3.6/tokenize.py\", line 381, in read_or_stop\n","    return readline()\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lEJMZKjH4ehJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"63cfa1d5-4825-4790-af66-61ad1098eb09","executionInfo":{"status":"ok","timestamp":1574116630975,"user_tz":420,"elapsed":30602,"user":{"displayName":"Erica Holswade","photoUrl":"","userId":"10344212883483634520"}}},"source":["drive.mount('/content/gdrive')\n","root_path = 'gdrive/My Drive/AppliedProject/'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rPpU8T134fLV","colab_type":"code","colab":{}},"source":["size = 600\n","training_path = 'gdrive/My Drive/AppliedProject/EasyData/Training'\n","test_path = 'gdrive/My Drive/AppliedProject/EasyData/Test'\n","\n","cnn_layers = [Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(size,size,3)), MaxPool2D(),\n","              Conv2D(64,(3,3),padding='same',activation='relu'), MaxPool2D(),\n","              Conv2D(128,(3,3),padding='same',activation='relu'), MaxPool2D(),\n","              Conv2D(128,(3,3),padding='same',activation='relu'), MaxPool2D(),\n","              Flatten(),Dense(100,activation='relu'),Dense(100,activation='relu'),Dense(2,activation='sigmoid')]\n","\n","classifier = keras.Sequential(cnn_layers)\n","\n","classifier.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3nQyePdHpuPX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"673a5e97-caf6-4539-db60-110f97abe5d6","executionInfo":{"status":"ok","timestamp":1574116653275,"user_tz":420,"elapsed":516,"user":{"displayName":"Erica Holswade","photoUrl":"","userId":"10344212883483634520"}}},"source":["train_datagen = ImageDataGenerator(rescale = 1./255,\n","shear_range = 0.2,\n","zoom_range = 0.2,\n","horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","training_set = train_datagen.flow_from_directory(training_path,\n","target_size = (size,size),\n","batch_size = 4,\n","class_mode = 'binary')\n","\n","test_set = test_datagen.flow_from_directory(test_path,\n","target_size = (size,size),\n","batch_size = 4,\n","class_mode = 'binary')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Found 400 images belonging to 2 classes.\n","Found 80 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MUQEMk59pwXN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"e50f3804-d3d3-495b-bec4-35b2eb80af76","executionInfo":{"status":"ok","timestamp":1574117305306,"user_tz":420,"elapsed":650418,"user":{"displayName":"Erica Holswade","photoUrl":"","userId":"10344212883483634520"}}},"source":["classifier.fit_generator(training_set,\n","steps_per_epoch = 50,\n","epochs = 3,\n","validation_data = test_set,\n","validation_steps = 5)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","50/50 [==============================] - 225s 5s/step - loss: 8.2359 - accuracy: 0.4750 - val_loss: 11.2827 - val_accuracy: 0.3000\n","Epoch 2/3\n","50/50 [==============================] - 211s 4s/step - loss: 7.8173 - accuracy: 0.5150 - val_loss: 11.2827 - val_accuracy: 0.3000\n","Epoch 3/3\n","50/50 [==============================] - 213s 4s/step - loss: 8.3814 - accuracy: 0.4800 - val_loss: 11.2827 - val_accuracy: 0.3000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f0cf2e67f60>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"qLbOx2ijpzO6","colab_type":"code","colab":{}},"source":["# test the NN on a single image\n","import numpy as np\n","from keras.preprocessing import image\n","test_image = image.load_img('gdrive/My Drive/AppliedProject/NewData/Test/Fake/easy_201_0001.jpg', target_size = (size,size))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = classifier.predict(test_image)\n","training_set.class_indices\n","print(result)\n","if result[0][0] == 1:\n","  prediction = 'fake'\n","else:\n","  prediction = 'real'\n","  \n","prediction"],"execution_count":0,"outputs":[]}]}