{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_Test2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras.datasets import cifar10, mnist\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n","from tensorflow.keras.layers import MaxPooling2D\n","import numpy as np\n","import scipy\n","#import matplotlib\n","#import matplotlib.pyplot as plt\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","np.random.seed(0)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"invalid character in identifier (<ipython-input-6-1c7c5962348a>, line 6)","output_type":"error","traceback":["\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-1c7c5962348a>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    Conv2D(64, (3, 3), input_shape=(size,size,3), padding='same', activation='relu'),\u001b[0m\n\u001b[1;37m                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"]}],"source":["size = 600\n","training_path = 'Z:\\School\\CSCI470\\deepfake_detect\\Images\\Training'\n","test_path = 'Z:\\School\\CSCI470\\deepfake_detect\\Images\\Test'\n","\n","cnn_layers = [\n","Conv2D(64, (3, 3), input_shape=(size,size,3), padding='same', activation='relu'),\n","Conv2D(64, (3, 3), activation='relu', padding='same'),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Conv2D(128, (3, 3), activation='relu', padding='same'),\n","Conv2D(128, (3, 3), activation='relu', padding='same',),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Conv2D(256, (3, 3), activation='relu', padding='same',),\n","Conv2D(256, (3, 3), activation='relu', padding='same',),\n","Conv2D(256, (3, 3), activation='relu', padding='same',),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Conv2D(512, (3, 3), activation='relu', padding='same',),\n","Conv2D(512, (3, 3), activation='relu', padding='same',),\n","Conv2D(512, (3, 3), activation='relu', padding='same',),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Conv2D(512, (3, 3), activation='relu', padding='same',),\n","Conv2D(512, (3, 3), activation='relu', padding='same',),\n","Conv2D(512, (3, 3), activation='relu', padding='same',),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Flatten(),\n","Dense(4096, activation='relu'),\n","Dense(4096, activation='relu'),\n","Dense(1000, activation='sigmoid')\n","]]\n","\n","\n","classifier = keras.Sequential(cnn_layers)\n","\n","classifier.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"colab_type":"code","executionInfo":{"elapsed":516,"status":"ok","timestamp":1574116653275,"user":{"displayName":"Erica Holswade","photoUrl":"","userId":"10344212883483634520"},"user_tz":420},"id":"3nQyePdHpuPX","outputId":"673a5e97-caf6-4539-db60-110f97abe5d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 400 images belonging to 2 classes.\n","Found 80 images belonging to 2 classes.\n"]}],"source":["train_datagen = ImageDataGenerator(rescale = 1./255,\n","shear_range = 0.2,\n","zoom_range = 0.2,\n","horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","training_set = train_datagen.flow_from_directory(training_path,\n","target_size = (size,size),\n","batch_size = 4,\n","class_mode = 'binary')\n","\n","test_set = test_datagen.flow_from_directory(test_path,\n","target_size = (size,size),\n","batch_size = 4,\n","class_mode = 'binary')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136},"colab_type":"code","executionInfo":{"elapsed":650418,"status":"ok","timestamp":1574117305306,"user":{"displayName":"Erica Holswade","photoUrl":"","userId":"10344212883483634520"},"user_tz":420},"id":"MUQEMk59pwXN","outputId":"e50f3804-d3d3-495b-bec4-35b2eb80af76"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","50/50 [==============================] - 225s 5s/step - loss: 8.2359 - accuracy: 0.4750 - val_loss: 11.2827 - val_accuracy: 0.3000\n","Epoch 2/3\n","50/50 [==============================] - 211s 4s/step - loss: 7.8173 - accuracy: 0.5150 - val_loss: 11.2827 - val_accuracy: 0.3000\n","Epoch 3/3\n","50/50 [==============================] - 213s 4s/step - loss: 8.3814 - accuracy: 0.4800 - val_loss: 11.2827 - val_accuracy: 0.3000\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f0cf2e67f60>"]},"execution_count":9,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["classifier.fit_generator(training_set,\n","steps_per_epoch = 50,\n","epochs = 3,\n","validation_data = test_set,\n","validation_steps = 5)"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"qLbOx2ijpzO6"},"outputs":[],"source":["# test the NN on a single image\n","import numpy as np\n","from keras.preprocessing import image\n","test_image = image.load_img('gdrive/My Drive/AppliedProject/NewData/Test/Fake/easy_201_0001.jpg', target_size = (size,size))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = classifier.predict(test_image)\n","training_set.class_indices\n","print(result)\n","if result[0][0] == 1:\n","  prediction = 'fake'\n","else:\n","  prediction = 'real'\n","  \n","prediction"]}]}