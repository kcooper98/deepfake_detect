{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_Test2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.datasets import cifar10, mnist\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n","from tensorflow.keras.layers import MaxPooling2D\n","import numpy as np\n","import scipy\n","import matplotlib\n","import h5py\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","np.random.seed(0)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#Code from StackExchange to fix \n","import sys \n","from PIL import Image\n","sys.modules['Image'] = Image "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"WARNING:tensorflow:From C:\\Users\\Mark\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From C:\\Users\\Mark\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"}],"source":["#Initialize the CNN\n","size = 64\n","cnn_layers = [Conv2D(64, (3, 3), input_shape=(size,size,3), padding='same', activation='relu'),\n","Conv2D(64, (3, 3), activation='relu', padding='same'),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Conv2D(128, (3, 3), activation='relu', padding='same'),\n","Conv2D(128, (3, 3), activation='relu', padding='same',),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Conv2D(256, (3, 3), activation='relu', padding='same',),\n","Conv2D(256, (3, 3), activation='relu', padding='same',),\n","Conv2D(256, (3, 3), activation='relu', padding='same',),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Conv2D(512, (3, 3), activation='relu', padding='same',),\n","Conv2D(512, (3, 3), activation='relu', padding='same',),\n","Conv2D(512, (3, 3), activation='relu', padding='same',),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Conv2D(512, (3, 3), activation='relu', padding='same',),\n","Conv2D(512, (3, 3), activation='relu', padding='same',),\n","Conv2D(512, (3, 3), activation='relu', padding='same',),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Flatten(),\n","Dense(4096, activation='relu'),\n","Dense(4096, activation='relu'),\n","Dense(1, activation='sigmoid')\n","]\n","\n","\n","\n","classifier = keras.Sequential(cnn_layers)\n","\n","classifier.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["#Used to artificially increase the size of the training data set\n","\n","#Blog.fkeras code for creating batches of randomly transformed images\n","#img = load_img('Z:\\School\\CSCI470\\deepfake_detect\\Images\\Training\\Faked\\Copy of 000000.png')  # this is a PIL image\n","#x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n","#x = x.reshape((1,) + x.shape)\n","\n","#i = 0\n","#for batch in datagen.flow(x, batch_size=1,\n","#                          save_to_dir='preview', save_prefix='Faked', save_format='jpeg'):\n","#    i += 1\n","#    if i > 20:\n","#        break"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Found 4000 images belonging to 2 classes.\nFound 1000 images belonging to 2 classes.\n[0 0 0 ... 1 1 1]\n"}],"source":["train_datagen = ImageDataGenerator(rescale = 1./255,\n","shear_range = 0.2,\n","zoom_range = 0.2,\n","horizontal_flip = True)\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","training_path = 'Z:\\\\School\\\\CSCI470\\\\deepfake_detect\\\\HardData2\\\\Train'\n","test_path = 'Z:\\\\School\\\\CSCI470\\\\deepfake_detect\\\\HardData2\\\\Validation'\n","\n","training_set = train_datagen.flow_from_directory(training_path,\n","target_size = (size,size),\n","batch_size = 25,\n","class_mode = 'binary')\n","\n","test_set = test_datagen.flow_from_directory(test_path,\n","target_size = (size,size),\n","batch_size = 25,\n","class_mode = 'binary')\n","\n","\n","\n","#Make sure labels are applied correctly\n","print(training_set.labels)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\nEpoch 1/20\n 99/100 [============================>.] - ETA: 3s - loss: 0.7121 - acc: 0.5087Epoch 1/20\n 10/100 [==>...........................] - ETA: 2:03 - loss: 0.6933 - acc: 0.4920WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\nWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n100/100 [==============================] - 343s 3s/step - loss: 0.7119 - acc: 0.5076 - val_loss: 0.6933 - val_acc: 0.4920\nEpoch 2/20\n 99/100 [============================>.] - ETA: 3s - loss: 0.6932 - acc: 0.5103Epoch 1/20\n 10/100 [==>...........................] - ETA: 1:50 - loss: 0.6933 - acc: 0.4920WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\nWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n100/100 [==============================] - 388s 4s/step - loss: 0.6932 - acc: 0.5096 - val_loss: 0.6933 - val_acc: 0.4920\nEpoch 3/20\n 99/100 [============================>.] - ETA: 3s - loss: 0.6932 - acc: 0.5034Epoch 1/20\n 10/100 [==>...........................] - ETA: 1:31 - loss: 0.6932 - acc: 0.4920WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\nWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n100/100 [==============================] - 350s 3s/step - loss: 0.6932 - acc: 0.5016 - val_loss: 0.6932 - val_acc: 0.4920\nEpoch 4/20\n 99/100 [============================>.] - ETA: 2s - loss: 0.6932 - acc: 0.4982Epoch 1/20\n 10/100 [==>...........................] - ETA: 1:32 - loss: 0.6931 - acc: 0.5080WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\nWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n100/100 [==============================] - 305s 3s/step - loss: 0.6932 - acc: 0.4972 - val_loss: 0.6931 - val_acc: 0.5080\nEpoch 5/20\n 99/100 [============================>.] - ETA: 3s - loss: 0.6932 - acc: 0.4788Epoch 1/20\n  7/100 [=>............................] - ETA: 2:52 - loss: 0.6931 - acc: 0.5314"}],"source":["checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","\n","early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n","\n","hist = classifier.fit_generator(steps_per_epoch=100,generator=training_set, validation_data= test_set, validation_steps=10,epochs=20,callbacks=[checkpoint,early])"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# test the NN on a single image\n","import numpy as np\n","from keras.preprocessing import image\n","test_image = image.load_img('gdrive/My Drive/AppliedProject/NewData/Test/Fake/easy_201_0001.jpg', target_size = (size,size))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = classifier.predict(test_image)\n","training_set.class_indices\n","print(result)\n","if result[0][0] == 1:\n","  prediction = 'fake'\n","else:\n","  prediction = 'real'\n","  \n","prediction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}