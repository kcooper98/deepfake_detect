{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_Test3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.datasets import cifar10, mnist\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n","from tensorflow.keras.layers import MaxPooling2D\n","import numpy as np\n","import scipy\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import zipfile\n","from zipfile import ZipFile\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.datasets import cifar10, mnist\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n","from tensorflow.keras.layers import MaxPooling2D\n","import numpy as np\n","import scipy\n","import matplotlib\n","import h5py\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","np.random.seed(0)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["#!pip install --upgrade tensorflow==2.0"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["#drive.mount(\"/content/gdrive\", force_remount=True)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["#with ZipFile('gdrive/My Drive/dogs-vs-cats/test1.zip', 'r') as zipObj:\n","   # Extract all the contents of zip file in current directory\n","   # zipObj.extractall('gdrive/My Drive/AppliedProject/HardBigData/Train/Real')"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["training_data_dir = 'Z:\\School\\CSCI470\\deepfake_detect\\HardData2\\Train'\n","validation_data_dir = 'Z:\\School\\CSCI470\\deepfake_detect\\HardData2\\Validation'\n","\n","BATCH_SIZE = 16\n","IMAGE_WIDTH = 64\n","IMAGE_HEIGHT = 64"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["#! ls /content/gdrive/\"My Drive\"/AppliedProject/DogCat2"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["training_data_generator = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.1,\n","    zoom_range=0.1,\n","    horizontal_flip=True)\n","validation_data_generator = ImageDataGenerator(rescale=1./255)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Found 4400 images belonging to 2 classes.\nFound 1080 images belonging to 2 classes.\n[0 0 0 ... 1 1 1]\n"}],"source":["training_generator = training_data_generator.flow_from_directory(\n","    training_data_dir,\n","    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n","    batch_size=BATCH_SIZE,\n","    class_mode=\"binary\")\n","validation_generator = validation_data_generator.flow_from_directory(\n","    validation_data_dir,\n","    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n","    batch_size=BATCH_SIZE,\n","    class_mode=\"binary\")\n","# shuffle=False)\n","\n","print(training_generator.labels)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["#Initialize the CNN\n","size = 64\n","cnn_layers = [Conv2D(8, (3, 3), input_shape=(size,size,3), padding='same', activation='relu'),\n","Conv2D(8, (3, 3), input_shape=(size,size,3), padding='same', activation='relu'),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Conv2D(16, (3, 3), activation='relu', padding='same'),\n","Conv2D(16, (3, 3), activation='relu', padding='same'),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Conv2D(32, (3, 3), activation='relu', padding='same'),\n","Conv2D(32, (3, 3), activation='relu', padding='same'),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Flatten(),\n","Dense(64, activation='relu'),\n","Dense(1, activation='sigmoid')\n","]\n","\n","\n","classifier = keras.Sequential(cnn_layers)\n","\n","classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["#Initialize the CNN\n","size = 64\n","cnn_layers = [Conv2D(8, (3, 3), input_shape=(size,size,3), padding='same', activation='relu'),\n","Conv2D(8, (3, 3), input_shape=(size,size,3), padding='same', activation='relu'),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Conv2D(16, (3, 3), activation='relu', padding='same'),\n","Conv2D(16, (3, 3), activation='relu', padding='same'),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Conv2D(32, (3, 3), activation='relu', padding='same'),\n","Conv2D(32, (3, 3), activation='relu', padding='same'),\n","MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n","Flatten(),\n","Dense(64, activation='relu'),\n","Dense(1, activation='sigmoid')\n","]\n","\n","\n","\n","classifier = keras.Sequential(cnn_layers)\n","\n","classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/20\n249/250 [============================>.] - ETA: 0s - loss: 0.6088 - acc: 0.6634Epoch 1/20\n250/250 [==============================] - 154s 616ms/step - loss: 0.6086 - acc: 0.6637 - val_loss: 0.4623 - val_acc: 0.8054\nEpoch 2/20\n249/250 [============================>.] - ETA: 0s - loss: 0.5021 - acc: 0.7658Epoch 1/20\n250/250 [==============================] - 148s 593ms/step - loss: 0.5035 - acc: 0.7653 - val_loss: 0.4038 - val_acc: 0.8286\nEpoch 3/20\n249/250 [============================>.] - ETA: 0s - loss: 0.4517 - acc: 0.7909Epoch 1/20\n250/250 [==============================] - 147s 589ms/step - loss: 0.4513 - acc: 0.7910 - val_loss: 0.3970 - val_acc: 0.8196\nEpoch 4/20\n249/250 [============================>.] - ETA: 0s - loss: 0.4337 - acc: 0.7959Epoch 1/20\n250/250 [==============================] - 139s 557ms/step - loss: 0.4339 - acc: 0.7958 - val_loss: 0.3861 - val_acc: 0.8226\nEpoch 5/20\n249/250 [============================>.] - ETA: 0s - loss: 0.3976 - acc: 0.8276Epoch 1/20\n250/250 [==============================] - 144s 575ms/step - loss: 0.3980 - acc: 0.8273 - val_loss: 0.3980 - val_acc: 0.8165\nEpoch 6/20\n249/250 [============================>.] - ETA: 0s - loss: 0.3830 - acc: 0.8313Epoch 1/20\n250/250 [==============================] - 146s 583ms/step - loss: 0.3829 - acc: 0.8310 - val_loss: 0.3204 - val_acc: 0.8639\nEpoch 7/20\n249/250 [============================>.] - ETA: 0s - loss: 0.3670 - acc: 0.8373Epoch 1/20\n250/250 [==============================] - 143s 571ms/step - loss: 0.3677 - acc: 0.8372 - val_loss: 0.3325 - val_acc: 0.8589\nEpoch 8/20\n249/250 [============================>.] - ETA: 0s - loss: 0.3388 - acc: 0.8532Epoch 1/20\n250/250 [==============================] - 139s 557ms/step - loss: 0.3389 - acc: 0.8530 - val_loss: 0.3392 - val_acc: 0.8488\nEpoch 9/20\n249/250 [============================>.] - ETA: 0s - loss: 0.3213 - acc: 0.8624Epoch 1/20\n250/250 [==============================] - 146s 583ms/step - loss: 0.3206 - acc: 0.8627 - val_loss: 0.3733 - val_acc: 0.8468\nEpoch 10/20\n249/250 [============================>.] - ETA: 0s - loss: 0.3123 - acc: 0.8604Epoch 1/20\n250/250 [==============================] - 145s 581ms/step - loss: 0.3120 - acc: 0.8605 - val_loss: 0.3437 - val_acc: 0.8599\nEpoch 11/20\n249/250 [============================>.] - ETA: 0s - loss: 0.3048 - acc: 0.8697Epoch 1/20\n250/250 [==============================] - 143s 573ms/step - loss: 0.3045 - acc: 0.8700 - val_loss: 0.3500 - val_acc: 0.8397\nEpoch 12/20\n249/250 [============================>.] - ETA: 0s - loss: 0.2969 - acc: 0.8727Epoch 1/20\n250/250 [==============================] - 150s 599ms/step - loss: 0.2974 - acc: 0.8725 - val_loss: 0.3221 - val_acc: 0.8700\nEpoch 13/20\n249/250 [============================>.] - ETA: 0s - loss: 0.2792 - acc: 0.8750Epoch 1/20\n250/250 [==============================] - 145s 582ms/step - loss: 0.2791 - acc: 0.8752 - val_loss: 0.3230 - val_acc: 0.8760\nEpoch 14/20\n249/250 [============================>.] - ETA: 0s - loss: 0.2700 - acc: 0.8838Epoch 1/20\n250/250 [==============================] - 151s 605ms/step - loss: 0.2692 - acc: 0.8842 - val_loss: 0.3100 - val_acc: 0.8770\nEpoch 15/20\n249/250 [============================>.] - ETA: 0s - loss: 0.2421 - acc: 0.8968Epoch 1/20\n250/250 [==============================] - 149s 595ms/step - loss: 0.2418 - acc: 0.8970 - val_loss: 0.2800 - val_acc: 0.8690\nEpoch 16/20\n249/250 [============================>.] - ETA: 0s - loss: 0.2598 - acc: 0.8908Epoch 1/20\n250/250 [==============================] - 149s 595ms/step - loss: 0.2592 - acc: 0.8910 - val_loss: 0.2807 - val_acc: 0.8861\nEpoch 17/20\n249/250 [============================>.] - ETA: 0s - loss: 0.2273 - acc: 0.9046Epoch 1/20\n250/250 [==============================] - 142s 569ms/step - loss: 0.2276 - acc: 0.9045 - val_loss: 0.3505 - val_acc: 0.8468\nEpoch 18/20\n249/250 [============================>.] - ETA: 0s - loss: 0.2409 - acc: 0.8951Epoch 1/20\n250/250 [==============================] - 140s 560ms/step - loss: 0.2404 - acc: 0.8955 - val_loss: 0.2735 - val_acc: 0.8841\nEpoch 19/20\n249/250 [============================>.] - ETA: 0s - loss: 0.2220 - acc: 0.9031Epoch 1/20\n250/250 [==============================] - 142s 568ms/step - loss: 0.2216 - acc: 0.9032 - val_loss: 0.2790 - val_acc: 0.8740\nEpoch 20/20\n249/250 [============================>.] - ETA: 0s - loss: 0.2094 - acc: 0.9119Epoch 1/20\n250/250 [==============================] - 140s 559ms/step - loss: 0.2089 - acc: 0.9120 - val_loss: 0.2841 - val_acc: 0.8952\n"},{"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x1ef196d6648>"},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["classifier.fit_generator(training_generator,\n","steps_per_epoch = 4000 // 16,\n","epochs = 20,\n","validation_data = validation_generator,\n","validation_steps = 1000 // 16)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: h5py in c:\\users\\mark\\anaconda3\\lib\\site-packages (2.8.0)\nRequirement already satisfied: pyyaml in c:\\users\\mark\\anaconda3\\lib\\site-packages (5.1.2)\nRequirement already satisfied: numpy>=1.7 in c:\\users\\mark\\anaconda3\\lib\\site-packages (from h5py) (1.17.3)\nRequirement already satisfied: six in c:\\users\\mark\\anaconda3\\lib\\site-packages (from h5py) (1.13.0)\n"}],"source":["!pip install h5py pyyaml"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["classifier.save('C:\\\\Users\\\\Mark\\\\Google Drive\\\\AppliedProject\\\\CNNModelMod3')\n"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["new_model = keras.models.load_model('C:\\Users\\Mark\\Google Drive\\AppliedProject\\CNNModelMod3')\n","new_model.summary()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'gdrive/My Drive/005000/005500.png'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-27-6a161f372642>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gdrive/My Drive/005000/005500.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIMAGE_WIDTH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mIMAGE_HEIGHT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[0;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'L'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2765\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2766\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gdrive/My Drive/005000/005500.png'"]}],"source":["# test the NN on a single image\n","import numpy as np\n","from keras.preprocessing import image\n","test_image = image.load_img('gdrive/My Drive/005000/005500.png', target_size = (IMAGE_WIDTH,IMAGE_HEIGHT))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = classifier.predict(test_image)\n","#training_set.class_indices\n","print(result)\n","if result[0][0] == 1:\n","  prediction = 'real'\n","else:\n","  prediction = 'fake'\n","  \n","prediction"]}]}